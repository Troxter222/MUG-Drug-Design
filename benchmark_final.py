import torch
import pandas as pd
import numpy as np
import json
import selfies as sf
from tqdm import tqdm
from rdkit import Chem
from rdkit.Chem import Descriptors, GraphDescriptors

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
from app.core.engine import MolecularVAE as GRU_Model
from app.core.transformer_model import MoleculeTransformer as Trans_Model
from app.core.vocab import Vocabulary
from app.services.chemistry import ChemistryService

# --- –ù–ê–°–¢–†–û–ô–ö–ò –ë–ò–¢–í–´ ---
SAMPLES_COUNT = 500  # –°–∫–æ–ª—å–∫–æ –º–æ–ª–µ–∫—É–ª –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 1. –ö–û–ù–§–ò–ì GRU (–¢–≤–æ–π —Å—Ç–∞—Ä—ã–π —á–µ–º–ø–∏–æ–Ω)
GRU_CFG = {
    "name": "Deep GRU (RL)",
    "path": "data/checkpoints_rl/mug_rl_best.pth", # –ü—Ä–æ–≤–µ—Ä—å –ø—É—Ç—å!
    "vocab": "data/processed/vocab_selfies.json",
    "params": {"vocab_size": 0, "embed_size": 64, "hidden_size": 256, "latent_size": 128, "num_layers": 3},
    "type": "gru"
}

# 2. –ö–û–ù–§–ò–ì TRANSFORMER (–¢–≤–æ–π –Ω–æ–≤—ã–π —á–µ–º–ø–∏–æ–Ω)
TRANS_CFG = {
    "name": "Transformer V2 (RL)",
    "path": "checkpoints_rl_transformer/mug_transformer_rl_best.pth", # –ü—Ä–æ–≤–µ—Ä—å –ø—É—Ç—å!
    "vocab": "dataset/processed/vocab_transformer.json",
    "params": {
        "vocab_size": 0, 
        "d_model": 256,   # <--- –ö–∞–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏ RL
        "nhead": 8, 
        "num_encoder_layers": 4, 
        "num_decoder_layers": 4, 
        "latent_size": 128, # <--- –ö–∞–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏ RL
        "dim_feedforward": 1024 
    },
    "type": "trans"
}

def load_vocab(path):
    with open(path, 'r') as f: chars = json.load(f)
    if '<sos>' not in chars: chars = ['<pad>', '<sos>', '<eos>'] + sorted(chars)
    return Vocabulary(chars)

def evaluate_model(config):
    print(f"\nü§ñ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {config['name']}...")
    
    if not os.path.exists(config['path']):
        print(f"‚ùå –§–∞–π–ª {config['path']} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return None

    # 1. Load Vocab
    vocab = load_vocab(config['vocab'])
    config['params']['vocab_size'] = len(vocab)
    
    # 2. Load Model
    if config['type'] == 'gru':
        model = GRU_Model(**config['params']).to(DEVICE)
    else:
        model = Trans_Model(**config['params']).to(DEVICE)
        
    try:
        model.load_state_dict(torch.load(config['path'], map_location=DEVICE))
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤: {e}")
        return None
        
    model.eval()
    
    # 3. Generation
    valid_mols = []
    unique_smiles = set()
    novelty_count = 0 # (–£–ø—Ä–æ—â–µ–Ω–Ω–æ, –±–µ–∑ —Å–≤–µ—Ä–∫–∏ —Å train)
    
    qeds = []
    sas = []
    mws = []
    tox_free = 0
    
    print(f"‚öóÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {SAMPLES_COUNT} –º–æ–ª–µ–∫—É–ª...")
    with torch.no_grad():
        for _ in tqdm(range(SAMPLES_COUNT)):
            try:
                if config['type'] == 'gru':
                    # GRU sample (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –æ–Ω –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–Ω–∑–æ—Ä [1, len])
                    idx = model.sample(1, DEVICE, vocab, max_len=120, temp=0.8)
                    if isinstance(idx, torch.Tensor): idx = idx.cpu().numpy()[0]
                else:
                    # Transformer sample
                    idx = model.sample(1, DEVICE, vocab, max_len=120, temp=0.8)
                    if isinstance(idx, torch.Tensor): idx = idx[0].cpu().numpy()
                
                # Decode
                selfies = vocab.decode(idx)
                smi = sf.decoder(selfies)
                if not smi: continue
                
                mol = Chem.MolFromSmiles(smi)
                if mol:
                    valid_mols.append(mol)
                    unique_smiles.add(smi)
                    
                    # Metrics
                    props = ChemistryService.analyze_properties(mol)
                    qeds.append(props['qed'])
                    mws.append(props['mw'])
                    sas.append(props['sa_score'])
                    
                    if "‚úÖ" in props['toxicity']:
                        tox_free += 1
            except: continue
            
    # 4. Aggregate
    total = SAMPLES_COUNT
    valid = len(valid_mols)
    
    metrics = {
        "Model": config['name'],
        "Validity": (valid / total) * 100,
        "Uniqueness": (len(unique_smiles) / valid * 100) if valid > 0 else 0,
        "Avg QED": np.mean(qeds) if qeds else 0,
        "Avg SA": np.mean(sas) if sas else 0,
        "Tox Free": (tox_free / valid * 100) if valid > 0 else 0,
        "Avg MW": np.mean(mws) if mws else 0
    }
    
    return metrics

import os

if __name__ == "__main__":
    results = []
    
    # Test GRU
    res_gru = evaluate_model(GRU_CFG)
    if res_gru: results.append(res_gru)
    
    # Test Transformer
    res_trans = evaluate_model(TRANS_CFG)
    if res_trans: results.append(res_trans)
    
    if results:
        df = pd.DataFrame(results)
        print("\n" + "="*60)
        print("üèÜ FINAL BENCHMARK RESULTS")
        print("="*60)
        print(df.to_string(index=False))
        df.to_csv("final_benchmark.csv", index=False)
        print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ final_benchmark.csv")
    else:
        print("‚ùå –¢–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ—à–ª–∏.")