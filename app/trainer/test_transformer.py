import torch
import json
import os
import glob
import pandas as pd
import selfies as sf
from rdkit import Chem
from rdkit.Chem import Draw, Descriptors
import matplotlib.pyplot as plt
from app.core.transformer_model import MoleculeTransformer

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø (–î–æ–ª–∂–Ω–∞ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å train_transformer.py) ---
class TestConfig:
    VOCAB_FILE = 'dataset/processed/vocab_transformer.json'
    CHECKPOINT_DIR = 'checkpoints_transformer'
    
    # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (–û–±—è–∑–∞–Ω–∞ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –æ–±—É—á–µ–Ω–∏–µ–º!)
    D_MODEL = 128
    NHEAD = 4
    LAYERS = 3
    LATENT = 64
    MAX_LEN = 150
    
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class SimpleVocab:
    def __init__(self, vocab_file):
        with open(vocab_file, 'r') as f:
            self.vocab = json.load(f)
        self.char2idx = {c: i for i, c in enumerate(self.vocab)}
        self.idx2char = {i: c for i, c in enumerate(self.vocab)}
        self.pad_idx = self.char2idx.get('<pad>', 0)
        self.sos_idx = self.char2idx.get('<sos>', 1)
        self.eos_idx = self.char2idx.get('<eos>', 2)

    def decode(self, indices):
        tokens = []
        for i in indices:
            idx = i.item() if torch.is_tensor(i) else i
            if idx == self.eos_idx: 
                break
            if idx != self.pad_idx and idx != self.sos_idx:
                tokens.append(self.idx2char[idx])
        return "".join(tokens)

def get_latest_checkpoint():
    """–ù–∞—Ö–æ–¥–∏—Ç —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π —Ñ–∞–π–ª –≤–µ—Å–æ–≤"""
    files = glob.glob(f"{TestConfig.CHECKPOINT_DIR}/*.pth")
    if not files:
        return None
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è (—Å–≤–µ–∂–∏–µ –≤ –∫–æ–Ω—Ü–µ)
    latest_file = max(files, key=os.path.getctime)
    return latest_file

def test():
    print("üî¨ –ó–ê–ü–£–°–ö –¢–ï–°–¢–ê –¢–†–ê–ù–°–§–û–†–ú–ï–†–ê...")
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è
    if not os.path.exists(TestConfig.VOCAB_FILE):
        print(f"‚ùå –°–ª–æ–≤–∞—Ä—å –Ω–µ –Ω–∞–π–¥–µ–Ω: {TestConfig.VOCAB_FILE}")
        return
    vocab = SimpleVocab(TestConfig.VOCAB_FILE)
    
    # 2. –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–∏
    ckpt_path = get_latest_checkpoint()
    if not ckpt_path:
        print(f"‚ùå –ß–µ–∫–ø–æ–∏–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {TestConfig.CHECKPOINT_DIR}. –ü–æ–¥–æ–∂–¥–∏ –æ–∫–æ–Ω—á–∞–Ω–∏—è 1-–π —ç–ø–æ—Ö–∏.")
        return
    
    print(f"üìÇ –ó–∞–≥—Ä—É–∂–∞—é –≤–µ—Å–∞: {ckpt_path}")
    
    # 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    model = MoleculeTransformer(
        vocab_size=len(vocab.vocab),
        d_model=TestConfig.D_MODEL,
        nhead=TestConfig.NHEAD,
        num_encoder_layers=TestConfig.LAYERS,
        num_decoder_layers=TestConfig.LAYERS,
        latent_size=TestConfig.LATENT
    ).to(TestConfig.DEVICE)
    
    model.load_state_dict(torch.load(ckpt_path, map_location=TestConfig.DEVICE))
    model.eval()
    
    # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
    NUM_SAMPLES = 50
    print(f"‚öóÔ∏è –ì–µ–Ω–µ—Ä–∏—Ä—É—é {NUM_SAMPLES} –º–æ–ª–µ–∫—É–ª...")
    
    valid_mols = []
    valid_smiles = []
    
    with torch.no_grad():
        for _ in range(NUM_SAMPLES):
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º 1 —à—Ç—É–∫—É (–º–æ–∂–Ω–æ –±–∞—Ç—á–∞–º–∏, –Ω–æ —Ç–∞–∫ –ø—Ä–æ—â–µ –¥–µ–±–∞–∂–∏—Ç—å)
            indices = model.sample(TestConfig.DEVICE, vocab, max_len=TestConfig.MAX_LEN)
            selfies_str = vocab.decode(indices)
            
            try:
                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º SELFIES -> SMILES
                smi = sf.decoder(selfies_str)
                if not smi: 
                    continue
                
                mol = Chem.MolFromSmiles(smi)
                if mol:
                    valid_mols.append(mol)
                    valid_smiles.append(smi)
            except Exception:
                continue

    # 5. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    validity = (len(valid_mols) / NUM_SAMPLES) * 100
    unique = len(set(valid_smiles))
    unique_ratio = (unique / len(valid_smiles) * 100) if valid_smiles else 0
    
    print("\nüìä –û–¢–ß–ï–¢ –û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ò:")
    print(f"‚úÖ –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å: {validity:.1f}% (–¶–µ–ª—å > 80%)")
    print(f"ü¶Ñ –£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å: {unique_ratio:.1f}%")
    
    if valid_mols:
        print("\nüß™ –ü—Ä–∏–º–µ—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:")
        for i in range(min(5, len(valid_smiles))):
            print(f"{i+1}. {valid_smiles[i]}")
            
        # –†–∏—Å—É–µ–º —Å–µ—Ç–∫—É
        img = Draw.MolsToGridImage(valid_mols[:9], molsPerRow=3, subImgSize=(300, 300), legends=[f"Mol {i+1}" for i in range(len(valid_mols[:9]))])
        img.save("transformer_test_results.png")
        print("\nüñº –ö–∞—Ä—Ç–∏–Ω–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ transformer_test_results.png")
        
        # –°—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π QED
        qeds = [Descriptors.qed(m) for m in valid_mols]
        avg_qed = sum(qeds) / len(qeds)
        print(f"üíä –°—Ä–µ–¥–Ω–∏–π QED (Drug-likeness): {avg_qed:.2f}")
    else:
        print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∞ —Ç–æ–ª—å–∫–æ –º—É—Å–æ—Ä. –ù—É–∂–Ω–æ —É—á–∏—Ç—å –¥–æ–ª—å—à–µ.")

if __name__ == "__main__":
    test()