import torch
import glob
import json
import os
import sys
import pandas as pd
import numpy as np
import selfies as sf
from tqdm import tqdm
from rdkit import Chem, DataStructs
from rdkit.Chem import Descriptors, Crippen, Lipinski, GraphDescriptors, AllChem

# --- –§–ò–ö–° –ò–ú–ü–û–†–¢–û–í ---
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# –ò–º–ø–æ—Ä—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
from app.core.engine import MolecularVAE
from app.core.transformer_model import MoleculeTransformer
from app.core.vocab import Vocabulary

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
SEARCH_DIRS = [
    "checkpoints_transformer", 
    "checkpoints_rl_transformer"
]
# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã —Å–ª–æ–≤–∞—Ä–µ–π
VOCAB_TRANS = "dataset/processed/vocab_transformer.json"

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class BenchmarkDebugger:
    def __init__(self):
        print(f"üîß Debug Mode. Device: {DEVICE}")

    def load_model(self, path):
        print(f"\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞: {path}")
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è
        try:
            with open(VOCAB_TRANS, 'r') as f: chars = json.load(f)
            # –§–∏–∫—Å —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤
            if '<sos>' not in chars: chars = ['<pad>', '<sos>', '<eos>'] + sorted(chars)
            vocab = Vocabulary(chars)
            print(f"   üìö –°–ª–æ–≤–∞—Ä—å: {len(vocab)} —Ç–æ–∫–µ–Ω–æ–≤")
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ —Å–ª–æ–≤–∞—Ä—è: {e}")
            return None, None

        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        try:
            checkpoint = torch.load(path, map_location=DEVICE)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤
            saved_vocab = checkpoint['embedding.weight'].shape[0]
            if saved_vocab != len(vocab):
                print(f"   ‚ö†Ô∏è MISMATCH: Vocab={len(vocab)}, Model={saved_vocab}. Using Model size.")
                current_vocab_len = saved_vocab
            else:
                current_vocab_len = len(vocab)

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä)
            model = MoleculeTransformer(
                vocab_size=current_vocab_len, 
                d_model=128, 
                nhead=4, 
                num_encoder_layers=3, 
                num_decoder_layers=3, 
                latent_size=64
            )
                
            model.load_state_dict(checkpoint)
            model.to(DEVICE)
            model.eval()
            print("   ‚úÖ –í–µ—Å–∞ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ.")
            return model, vocab
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤: {e}")
            return None, None

    def test_generation(self, model, vocab):
        print("   üß™ –ü–æ–ø—ã—Ç–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")
        try:
            with torch.no_grad():
                # –ü—Ä–æ–±—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å 1 –º–æ–ª–µ–∫—É–ª—É –∏ —Å–º–æ—Ç—Ä–∏–º, –≥–¥–µ —É–ø–∞–¥–µ—Ç
                indices = model.sample(DEVICE, vocab, max_len=100)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–µ—Ä–Ω—É–ª–æ—Å—å
                if isinstance(indices, torch.Tensor):
                    indices = indices.cpu().numpy().tolist()
                
                print(f"   üî¢ Indices received: {indices[:5]}...")
                
                decoded = vocab.decode(torch.tensor(indices))
                print(f"   üî§ Decoded SELFIES: {decoded}")
                
                smi = sf.decoder(decoded)
                print(f"   üß¨ SMILES: {smi}")
                
                mol = Chem.MolFromSmiles(smi)
                if mol:
                    print("   üéâ SUCCESS: Valid Molecule!")
                    return True
                else:
                    print("   ‚ö†Ô∏è Invalid Molecule (RDKit failed)")
                    return False
                    
        except Exception as e:
            print(f"   üî• CRASH DURING GENERATION: {e}")
            import traceback
            traceback.print_exc()
            return False

    def run(self):
        files = []
        for d in SEARCH_DIRS:
            files.extend(glob.glob(os.path.join(d, "*.pth")))
            
        if not files:
            print("‚ùå –§–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            return

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –¥–µ–±–∞–≥–∞
        print(f"üîé –ù–∞–π–¥–µ–Ω–æ {len(files)} —Ñ–∞–π–ª–æ–≤. –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–π...")
        f = files[0] # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –ø–æ–ø–∞–≤—à–∏–π—Å—è
        
        model, vocab = self.load_model(f)
        if model:
            self.test_generation(model, vocab)

if __name__ == "__main__":
    BenchmarkDebugger().run()